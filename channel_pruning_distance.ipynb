{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba20d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Provides basic tensor operation and nn operation\n",
    "import load_dataset as dl  # create dataloader for selected dataset\n",
    "import load_model as lm  # facilitate loading and manipulating models\n",
    "import train_model as tm  # Facilitate training of the model\n",
    "import initialize_pruning as ip  # Initialize and provide basic parameter require for pruning\n",
    "import facilitate_pruning as fp  # Compute Pruning Value and many things\n",
    "import torch.nn.utils.prune as prune\n",
    "import os  # use to access the files\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5beedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/pragnesh/project/Dataset/'; selected_dataset_dir = 'IntelIC'\n",
    "train_folder = 'train'; test_folder = 'test'\n",
    "\n",
    "# String Parameter for Model\n",
    "loadModel = False; is_transfer_learning = False\n",
    "\n",
    "program_name = 'vgg_net_kernel_pruning_3Aug'; model_dir = '/home/pragnesh/project/Model/'\n",
    "selectedModel = 'vgg16_IntelIc_Prune'\n",
    "load_path = f'{model_dir}{program_name}/{selected_dataset_dir}/{selectedModel}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c10f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String parameter to Log Output\n",
    "logDir = '/home/pragnesh/project/Logs/'\n",
    "folder_path = f'{logDir}{program_name}/{selected_dataset_dir}/'\n",
    "logResultFile = f'{folder_path}result.log'\n",
    "outFile = f'{folder_path}lastResult.log'\n",
    "outLogFile = f'{folder_path}outLogFile.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ffb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device1 = torch.device('cuda')\n",
    "else:\n",
    "    device1 = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75131ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(dir_path):\n",
    "    directory = os.path.dirname(dir_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436259ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir(f'{model_dir}{program_name}/')  # dir /home/pragnesh/project/Model/vgg_net_kernel_pruning_3Aug/\n",
    "ensure_dir(f'{model_dir}{program_name}/{selected_dataset_dir}/')  # dir ~/vgg_net_kernel_pruning_3Aug/IntelIc/\n",
    "ensure_dir(f'{logDir}{program_name}')  # dir /home/pragnesh/project/Logs/program_name/\n",
    "ensure_dir(f'{logDir}{program_name}/{selected_dataset_dir}/')  # dir /home/pragnesh/project/Logs/program_name/IntelIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.set_image_size(224)\n",
    "dl.set_batch_size = 16\n",
    "dataLoaders = dl.data_loader(set_datasets_arg=dataset_dir, selected_dataset_arg=selected_dataset_dir,\n",
    "                             train_arg=train_folder, test_arg=test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f70580",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModel:  # Load the saved trained model\n",
    "    new_model = torch.load(load_path, map_location=torch.device(device1))\n",
    "else:  # Load the standard model from library\n",
    "    # if we don't have any saved trained model download pretrained model for transfer learning\n",
    "    new_model = lm.load_model(model_name='vgg16', number_of_class=6, pretrainval=is_transfer_learning,\n",
    "                              freeze_feature_arg=False, device_l=device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "d1 = today.strftime(\"%d-%m\")\n",
    "print(f\"\\n...........OutLog For the {d1}................\")\n",
    "with open(outLogFile, 'a') as f:\n",
    "    f.write(f\"\\n\\n..........................OutLog For the {d1}......................\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_list = []; feature_list = []; conv_layer_index = []; module = []\n",
    "prune_count = []; new_list = []; candidate_conv_layer = []\n",
    "layer_number = 0; st = 0; en = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c724c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lists_for_pruning():\n",
    "    global block_list, feature_list, conv_layer_index, module, prune_count, new_list, candidate_conv_layer\n",
    "    global layer_number, st, en\n",
    "    block_list = ip.create_block_list(new_model)  # ip.getBlockList('vgg16')\n",
    "    feature_list = ip.create_feature_list(new_model)\n",
    "    conv_layer_index = ip.find_conv_index(new_model)\n",
    "    module = ip.make_list_conv_param(new_model)\n",
    "    prune_count = ip.get_prune_count(module=module, blocks=block_list, max_pr=.1)\n",
    "    new_list = []\n",
    "    layer_number = 0\n",
    "    st = 0\n",
    "    en = 0\n",
    "    candidate_conv_layer = []\n",
    "\n",
    "initialize_lists_for_pruning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb97e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_layer_dist_channel_pruning(module_cand_conv, block_list_l, block_id):\n",
    "    global layer_number\n",
    "    candidate_convolution_layer = []\n",
    "    end_index = 0\n",
    "    for bl in range(len(block_list_l)):\n",
    "        start_index = end_index\n",
    "        end_index = end_index + block_list_l[bl]\n",
    "        if bl != block_id:\n",
    "            continue\n",
    "\n",
    "        with open(outLogFile, \"a\") as out_file:\n",
    "            out_file.write(f'\\nblock ={bl} blockSize={block_list_l[bl]}, start={start_index}, End={end_index}')\n",
    "        out_file.close()\n",
    "        # newList = []\n",
    "        # candidList = []\n",
    "        for lno in range(start_index, end_index):\n",
    "            # layer_number =st+i\n",
    "            with open(outLogFile, 'a') as out_file:\n",
    "                out_file.write(f\"\\nlno in compute candidate {lno}\")\n",
    "            out_file.close()\n",
    "            candidate_convolution_layer.append(fp.compute_distance_score_channel(\n",
    "                module_cand_conv[lno]._parameters['weight'],\n",
    "                n=1,\n",
    "                dim_to_keep=[0],\n",
    "                prune_amount=prune_count[lno]))\n",
    "        break\n",
    "    return candidate_convolution_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c04031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelPruningMethodSimilarities(prune.BasePruningMethod):\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        with open(outLogFile, \"a\") as log_file:\n",
    "            log_file.write(\"\\n Executing Compute Mask\")\n",
    "        log_file.close()\n",
    "        mask = default_mask.clone()\n",
    "        # mask.view(-1)[::2] = 0\n",
    "        size = t.shape\n",
    "        print(f\"\\n{size}\")\n",
    "        with open(outLogFile, \"a\") as log_file:\n",
    "            log_file.write(f'\\nLayer Number:{layer_number} \\nstart={st} \\nlength of new list={len(new_list)}')\n",
    "        log_file.close()\n",
    "        for k1 in range(len(new_list)):\n",
    "            for k2 in range(len(new_list[layer_number - st][k1])):\n",
    "                i = new_list[layer_number - st][k1][k2][1]\n",
    "                j = new_list[layer_number - st][k1][k2][0]\n",
    "                if k1 == j:\n",
    "                    print(\":\", end='')\n",
    "                # print(f\"i= {i} , j= {j}\")\n",
    "\n",
    "                mask[i][j] = 0\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ef646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_unstructured_similarities(kernel_module, name):\n",
    "    ChannelPruningMethodSimilarities.apply(kernel_module, name)\n",
    "    return kernel_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc938e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
